* https://developers.googleblog.com/en/introducing-gemma-3-270m/
* Misalignment/Evil: https://www.quantamagazine.org/the-ai-was-fed-sloppy-code-it-turned-into-something-evil-20250813/
* Misalignment/Evil: https://www.livescience.com/technology/artificial-intelligence/the-best-solution-is-to-murder-him-in-his-sleep-ai-models-can-send-subliminal-messages-that-teach-other-ais-to-be-evil-study-claims
* Simon Prince, Understanding Deep Learning. https://udlbook.github.io/udlbook/ Liang, Shiyu, and Rayadurgam Srikant. 
* Chain of Thought: https://arxiv.org/pdf/2508.01191
* "Why deep neural networks for function approximation?." arXiv preprint arXiv:1610.04161 (2016). Hanin, Boris, and David Rolnick. 
* "Deep relu networks have surprisingly few activation patterns." Advances in neural information processing systems 32 (2019). Hanin, Boris, and David Rolnick. 
* "Complexity of linear regions in deep networks." *International Conference on Machine Learning*. PMLR, 2019. Fan, Feng-Lei, et al. 
* "Deep relu networks have surprisingly simple polytopes." arXiv preprint arXiv:2305.09145 (2023).